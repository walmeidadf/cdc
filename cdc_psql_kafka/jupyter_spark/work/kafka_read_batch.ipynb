{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a20cd12c-a60e-452d-9d9f-dac62f76bdb9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b3a2c21-e00f-482e-b599-d8b4643cbb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "from delta.tables import *\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "tz = timezone(\"America/Sao_Paulo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9e605c-dfcc-4c95-81c6-6695a13f09ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Build a Spark Session\n",
    "The entry point to programming Spark with the Dataset and DataFrame API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "241a3957-b1e9-4f2b-bad5-67acd4a21940",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.1,io.delta:delta-core_2.12:1.2.1\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .appName(\"LabCDC\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2f02ae9-1101-4489-bdcf-21622d2c92b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://localhost:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>LabCDC</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=LabCDC>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show some information about the spark context and get url for Spark UI\n",
    "spark._sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f31c28-607b-4a67-bd4c-cf86763d5767",
   "metadata": {},
   "source": [
    "### Consume messages from kafka topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85b62688-05d8-4520-90b9-35190ae9702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Sqpark DataFrame from Kafka topic\n",
    "df = spark \\\n",
    "  .read \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"kafka-1:9092\") \\\n",
    "  .option(\"subscribe\", \"lab_cdc.inventory.customers\") \\\n",
    "  .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec02516d-c3b7-451f-ac12-d0bc0cb33ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8092581-7efc-421e-8a14-f20b68ea2808",
   "metadata": {},
   "source": [
    "### Exploring kafka message structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bcd3b76-46a7-4bee-934d-fe50a385f5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, list, pyspark.sql.types.Row)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collecting data from Spark DataFrame into a list of pyspark Row\n",
    "kafka_data = df.collect()\n",
    "\n",
    "# printing some information\n",
    "len(kafka_data), type(kafka_data), type(kafka_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1a51716-a324-4f3e-94f0-d8bd87ac3bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['key', 'value', 'topic', 'partition', 'offset', 'timestamp', 'timestampType'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing the dict keys from the Rows\n",
    "kafka_data[0].asDict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "174c3f5f-417e-48fe-8da3-f564d1267cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Topic:          lab_cdc.inventory.customers\n",
      " Partition:      2\n",
      " Offset:         3\n",
      " Timestamp:      2022-04-29 19:46:19.458000\n",
      " Timestamp Type: 0\n"
     ]
    }
   ],
   "source": [
    "# Showing the values of topic, partition, offset, timestamp, and timestampType from the first Row\n",
    "print(' Topic:          {}\\n'.format(kafka_data[0]['topic']),\\\n",
    "      'Partition:      {}\\n'.format(kafka_data[0]['partition']),\\\n",
    "      'Offset:         {}\\n'.format( kafka_data[0]['offset']),\\\n",
    "      'Timestamp:      {}\\n'.format(kafka_data[0]['timestamp']),\\\n",
    "      'Timestamp Type: {}'.format(kafka_data[0]['timestampType']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3a8f6be-5a19-434f-a9e0-3913b273417b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key\n",
      " {\n",
      "    \"payload\": {\n",
      "        \"id\": 2\n",
      "    },\n",
      "    \"schema\": {\n",
      "        \"fields\": [\n",
      "            {\n",
      "                \"default\": 0,\n",
      "                \"field\": \"id\",\n",
      "                \"optional\": false,\n",
      "                \"type\": \"int32\"\n",
      "            }\n",
      "        ],\n",
      "        \"name\": \"lab_cdc.inventory.customers.Key\",\n",
      "        \"optional\": false,\n",
      "        \"type\": \"struct\"\n",
      "    }\n",
      "} \n",
      "\n",
      "Value\n",
      " {\n",
      "    \"payload\": {\n",
      "        \"after\": {\n",
      "            \"email\": \"gbailey@foobar.com\",\n",
      "            \"first_name\": \"George\",\n",
      "            \"id\": 2,\n",
      "            \"last_name\": \"Bailey\"\n",
      "        },\n",
      "        \"before\": null,\n",
      "        \"op\": \"r\",\n",
      "        \"source\": {\n",
      "            \"connector\": \"postgresql\",\n",
      "            \"db\": \"postgres\",\n",
      "            \"lsn\": 24279104,\n",
      "            \"name\": \"lab_cdc\",\n",
      "            \"schema\": \"inventory\",\n",
      "            \"sequence\": \"[null,\\\"24279104\\\"]\",\n",
      "            \"snapshot\": \"true\",\n",
      "            \"table\": \"customers\",\n",
      "            \"ts_ms\": 1651261553960,\n",
      "            \"txId\": 738,\n",
      "            \"version\": \"1.9.2.Final\",\n",
      "            \"xmin\": null\n",
      "        },\n",
      "        \"transaction\": null,\n",
      "        \"ts_ms\": 1651261553961\n",
      "    },\n",
      "    \"schema\": {\n",
      "        \"fields\": [\n",
      "            {\n",
      "                \"field\": \"before\",\n",
      "                \"fields\": [\n",
      "                    {\n",
      "                        \"default\": 0,\n",
      "                        \"field\": \"id\",\n",
      "                        \"optional\": false,\n",
      "                        \"type\": \"int32\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"first_name\",\n",
      "                        \"optional\": true,\n",
      "                        \"type\": \"string\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"last_name\",\n",
      "                        \"optional\": true,\n",
      "                        \"type\": \"string\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"email\",\n",
      "                        \"optional\": true,\n",
      "                        \"type\": \"string\"\n",
      "                    }\n",
      "                ],\n",
      "                \"name\": \"lab_cdc.inventory.customers.Value\",\n",
      "                \"optional\": true,\n",
      "                \"type\": \"struct\"\n",
      "            },\n",
      "            {\n",
      "                \"field\": \"after\",\n",
      "                \"fields\": [\n",
      "                    {\n",
      "                        \"default\": 0,\n",
      "                        \"field\": \"id\",\n",
      "                        \"optional\": false,\n",
      "                        \"type\": \"int32\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"first_name\",\n",
      "                        \"optional\": true,\n",
      "                        \"type\": \"string\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"last_name\",\n",
      "                        \"optional\": true,\n",
      "                        \"type\": \"string\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"email\",\n",
      "                        \"optional\": true,\n",
      "                        \"type\": \"string\"\n",
      "                    }\n",
      "                ],\n",
      "                \"name\": \"lab_cdc.inventory.customers.Value\",\n",
      "                \"optional\": true,\n",
      "                \"type\": \"struct\"\n",
      "            },\n",
      "            {\n",
      "                \"field\": \"source\",\n",
      "                \"fields\": [\n",
      "                    {\n",
      "                        \"field\": \"version\",\n",
      "                        \"optional\": false,\n",
      "                        \"type\": \"string\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"connector\",\n",
      "                        \"optional\": false,\n",
      "                        \"type\": \"string\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"name\",\n",
      "                        \"optional\": false,\n",
      "                        \"type\": \"string\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"ts_ms\",\n",
      "                        \"optional\": false,\n",
      "                        \"type\": \"int64\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"default\": \"false\",\n",
      "                        \"field\": \"snapshot\",\n",
      "                        \"name\": \"io.debezium.data.Enum\",\n",
      "                        \"optional\": true,\n",
      "                        \"parameters\": {\n",
      "                            \"allowed\": \"true,last,false,incremental\"\n",
      "                        },\n",
      "                        \"type\": \"string\",\n",
      "                        \"version\": 1\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"db\",\n",
      "                        \"optional\": false,\n",
      "                        \"type\": \"string\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"sequence\",\n",
      "                        \"optional\": true,\n",
      "                        \"type\": \"string\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"schema\",\n",
      "                        \"optional\": false,\n",
      "                        \"type\": \"string\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"table\",\n",
      "                        \"optional\": false,\n",
      "                        \"type\": \"string\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"txId\",\n",
      "                        \"optional\": true,\n",
      "                        \"type\": \"int64\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"lsn\",\n",
      "                        \"optional\": true,\n",
      "                        \"type\": \"int64\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"xmin\",\n",
      "                        \"optional\": true,\n",
      "                        \"type\": \"int64\"\n",
      "                    }\n",
      "                ],\n",
      "                \"name\": \"io.debezium.connector.postgresql.Source\",\n",
      "                \"optional\": false,\n",
      "                \"type\": \"struct\"\n",
      "            },\n",
      "            {\n",
      "                \"field\": \"op\",\n",
      "                \"optional\": false,\n",
      "                \"type\": \"string\"\n",
      "            },\n",
      "            {\n",
      "                \"field\": \"ts_ms\",\n",
      "                \"optional\": true,\n",
      "                \"type\": \"int64\"\n",
      "            },\n",
      "            {\n",
      "                \"field\": \"transaction\",\n",
      "                \"fields\": [\n",
      "                    {\n",
      "                        \"field\": \"id\",\n",
      "                        \"optional\": false,\n",
      "                        \"type\": \"string\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"total_order\",\n",
      "                        \"optional\": false,\n",
      "                        \"type\": \"int64\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"data_collection_order\",\n",
      "                        \"optional\": false,\n",
      "                        \"type\": \"int64\"\n",
      "                    }\n",
      "                ],\n",
      "                \"optional\": true,\n",
      "                \"type\": \"struct\"\n",
      "            }\n",
      "        ],\n",
      "        \"name\": \"lab_cdc.inventory.customers.Envelope\",\n",
      "        \"optional\": false,\n",
      "        \"type\": \"struct\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Showing the Key and Value from the first Row\n",
    "print('Key\\n', json.dumps(json.loads(kafka_data[0]['key']), indent=4, sort_keys=True), \\\n",
    "      '\\n\\nValue\\n',  json.dumps(json.loads(kafka_data[0]['value']), indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07bb9a05-c4d1-4d25-ad02-3dbac9c8d916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'before': None,\n",
       " 'after': {'id': 2,\n",
       "  'first_name': 'George',\n",
       "  'last_name': 'Bailey',\n",
       "  'email': 'gbailey@foobar.com'},\n",
       " 'source': {'version': '1.9.2.Final',\n",
       "  'connector': 'postgresql',\n",
       "  'name': 'lab_cdc',\n",
       "  'ts_ms': 1651261553960,\n",
       "  'snapshot': 'true',\n",
       "  'db': 'postgres',\n",
       "  'sequence': '[null,\"24279104\"]',\n",
       "  'schema': 'inventory',\n",
       "  'table': 'customers',\n",
       "  'txId': 738,\n",
       "  'lsn': 24279104,\n",
       "  'xmin': None},\n",
       " 'op': 'r',\n",
       " 'ts_ms': 1651261553961,\n",
       " 'transaction': None}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Value keys has two new keys: payload and schema\n",
    "# the schema key is verbose and show a lot of important information about the data\n",
    "# now we show just the payload key from the First Row\n",
    "json.loads(kafka_data[0]['value'])['payload']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0787d80f-1aca-4b99-bcae-9449abeba34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['before', 'after', 'source', 'op', 'ts_ms', 'transaction'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing the keys below of payload\n",
    "json.loads(kafka_data[0]['value'])['payload'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49de2cae-18ae-467d-97ba-4f1bb3473a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the 'op' key describes the type of operation that caused the connector to generate the event\n",
    "# ref: https://debezium.io/documentation/reference/stable/connectors/postgresql.html#postgresql-create-events\n",
    "json.loads(kafka_data[0]['value'])['payload']['op']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d97da41-5401-45e9-9d35-f2363655ae60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 2,\n",
       " 'first_name': 'George',\n",
       " 'last_name': 'Bailey',\n",
       " 'email': 'gbailey@foobar.com'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(kafka_data[0]['value'])['payload']['after']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b670317-d66d-427e-b38a-dd6c915094be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'version': '1.9.2.Final',\n",
       " 'connector': 'postgresql',\n",
       " 'name': 'lab_cdc',\n",
       " 'ts_ms': 1651261553960,\n",
       " 'snapshot': 'true',\n",
       " 'db': 'postgres',\n",
       " 'sequence': '[null,\"24279104\"]',\n",
       " 'schema': 'inventory',\n",
       " 'table': 'customers',\n",
       " 'txId': 738,\n",
       " 'lsn': 24279104,\n",
       " 'xmin': None}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(kafka_data[0]['value'])['payload']['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa39dc21-2c20-49a4-b048-bc68b582c744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r 2 George Bailey gbailey@foobar.com\n",
      "r 3 Edward Walker ed@walker.com\n",
      "r 4 Jonh Kretchmar annek@noanswer.org\n",
      "r 2 George Bailey gbailey@foobar.com\n",
      "r 3 Edward Walker ed@walker.com\n",
      "r 4 Jonh Kretchmar annek@noanswer.org\n",
      "r 1 Sally Thomas sally.thomas@acme.com\n",
      "r 1 Sally Thomas sally.thomas@acme.com\n"
     ]
    }
   ],
   "source": [
    "for row in kafka_data:\n",
    "    # print(str(row[0]) + \",\" + str(row[1]))\n",
    "    json_value = json.loads(row[1])\n",
    "    # print(json_value['payload'])\n",
    "    op         = json_value['payload']['op']\n",
    "    user_id    = json_value['payload']['after']['id']\n",
    "    first_name = json_value['payload']['after']['first_name']\n",
    "    last_name  = json_value['payload']['after']['last_name']\n",
    "    email      = json_value['payload']['after']['email']\n",
    "    print(op, user_id, first_name, last_name, email)\n",
    "    # print(json_value['payload']['op'] + \",\" + str(json_value['payload']['id']) + \",\" + json_value['payload']['first_name'] + \",\" + json_value['payload']['last_name'] + \",\" + json_value['payload']['email'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9453a340-5fc4-44f6-8f6a-7fe7c7280bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['before', 'after', 'source', 'op', 'ts_ms', 'transaction']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicts = json.loads(kafka_data[0]['value'])['schema']['fields']\n",
    "[x['field'] for x in dicts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc0ed0a0-24a5-4f5d-a3e1-5fcd8a8e6fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'struct',\n",
       " 'fields': [{'type': 'int32', 'optional': False, 'default': 0, 'field': 'id'},\n",
       "  {'type': 'string', 'optional': True, 'field': 'first_name'},\n",
       "  {'type': 'string', 'optional': True, 'field': 'last_name'},\n",
       "  {'type': 'string', 'optional': True, 'field': 'email'}],\n",
       " 'optional': True,\n",
       " 'name': 'lab_cdc.inventory.customers.Value',\n",
       " 'field': 'after'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(item for item in dicts if item[\"field\"] == \"after\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4691b7-37d0-4b9b-9767-fb8e69785f7a",
   "metadata": {},
   "source": [
    "### Saving data into a Delta Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "406a1743-cfe5-4355-865e-40779c76937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a path location where the table will be created\n",
    "location = \"/delta_lake/customers\"\n",
    "# Create or replace table with path and add properties\n",
    "deltaTable = DeltaTable.createOrReplace(spark) \\\n",
    "  .addColumn(\"kafka_key\", \"STRING\") \\\n",
    "  .addColumn(\"kafka_offset\", \"BIGINT\") \\\n",
    "  .addColumn(\"id\", \"BIGINT\") \\\n",
    "  .addColumn(\"first_name\", \"STRING\") \\\n",
    "  .addColumn(\"last_name\", \"STRING\") \\\n",
    "  .addColumn(\"email\", \"STRING\") \\\n",
    "  .addColumn(\"created_at\", \"TIMESTAMP\") \\\n",
    "  .addColumn(\"updated_at\", \"TIMESTAMP\") \\\n",
    "  .property(\"description\", \"table with customers data\") \\\n",
    "  .location(location) \\\n",
    "  .execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "108b8b62-308b-471b-af48-1e9edec75dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 12\n",
      "drwxr-xr-x 3 jovyan users 4096 May  1 20:37 .\n",
      "drwxrwxr-x 3 jovyan  1000 4096 May  1 20:37 ..\n",
      "drwxr-xr-x 2 jovyan users 4096 May  1 20:37 _delta_log\n"
     ]
    }
   ],
   "source": [
    "!ls {location} -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c57e3036-ee59-4443-8b7d-db37342202eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para fazer extracao de schema dinamica das mensagens do kafka\n",
    "def infer_schema_json(kafka_df):\n",
    "    df_json = (\n",
    "        # filter out empty values\n",
    "        kafka_df.withColumn(\"value\", F.expr(\"string(value)\"))\n",
    "        .filter(F.col(\"value\").isNotNull())\n",
    "        # get latestecord\n",
    "        .select(\"key\", F.expr(\"struct(offset, value) r\"))\n",
    "        .groupBy(\"key\").agg(F.expr(\"max(r) r\")) \n",
    "        .select(\"r.value\"))\n",
    "\n",
    "    # decode the json values\n",
    "    df_read = spark.read.json(df_json.rdd.map(lambda x: x.value), multiLine=True)\n",
    "\n",
    "    # drop corrupt records\n",
    "    if \"_corrupt_record\" in df_read.columns:\n",
    "        df_read = (df_read.filter(col(\"_corrupt_record\").isNotNull()).drop(\"_corrupt_record\"))\n",
    "\n",
    "    # schema\n",
    "    return df_read.schema.json()\n",
    "\n",
    "# passa o data frame de leitura do kafka para fazer a inferencia do schema para um formato json\n",
    "# cria um objeto do tipo pyspark.sql.types.StructType a partir do json\n",
    "topic_schema_txt = infer_schema_json(df)\n",
    "topic_schema = StructType.fromJson(json.loads(topic_schema_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66689259-ef98-4ff4-82a3-a83833780708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema\n",
      "\n",
      "root\n",
      " |-- kafka_key: string (nullable = true)\n",
      " |-- kafka_offset: long (nullable = true)\n",
      " |-- created_at: timestamp (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      "\n",
      "\n",
      "Records\n",
      "\n",
      "+--------------------+------------+--------------------+--------------------+----------+---+---------+\n",
      "|           kafka_key|kafka_offset|          created_at|               email|first_name| id|last_name|\n",
      "+--------------------+------------+--------------------+--------------------+----------+---+---------+\n",
      "|{\"schema\":{\"type\"...|           2|2022-05-01 14:33:...|sally.thomas@acme...|     Sally|  1|   Thomas|\n",
      "|{\"schema\":{\"type\"...|           6|2022-05-01 14:33:...|  gbailey@foobar.com|    George|  2|   Bailey|\n",
      "|{\"schema\":{\"type\"...|           7|2022-05-01 14:33:...|       ed@walker.com|    Edward|  3|   Walker|\n",
      "|{\"schema\":{\"type\"...|           8|2022-05-01 14:33:...|  annek@noanswer.org|      Jonh|  4|Kretchmar|\n",
      "+--------------------+------------+--------------------+--------------------+----------+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select columns from messages' payload and enforce unique kafka key\n",
    "dfw = df \\\n",
    "      .withColumn(\"value\", F.expr(\"string(value)\"))\\\n",
    "      .filter(F.col(\"value\").isNotNull())\\\n",
    "      .select(\\\n",
    "         F.expr(\"offset as kafka_offset\"),\\\n",
    "         F.expr(\"timestamp as created_at\"),\\\n",
    "         F.expr(\"string(key) as kafka_key\"),\\\n",
    "         \"value\")\\\n",
    "      .select(\"kafka_key\", F.expr(\"struct(*) as r\"))\\\n",
    "      .groupBy(\"kafka_key\")\\\n",
    "      .agg(F.expr(\"max(r) r\"))\\\n",
    "      .withColumn('value', F.from_json(F.col(\"r.value\"), topic_schema))\\\n",
    "      .select('r.kafka_key', 'r.kafka_offset', 'r.created_at', 'value.payload.after.*')\n",
    "print(\"Schema\\n\")\n",
    "dfw.printSchema()\n",
    "print(\"\\nRecords\\n\")\n",
    "dfw.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63bc6d49-fbb0-4c0d-b4ca-e238ea165f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add kafka data to an existing Delta table using append mode\n",
    "dfw.write.format(\"delta\").mode(\"append\").save(location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f779551-9557-451c-a1c9-84b789e019c2",
   "metadata": {},
   "source": [
    "### Visualize delta lake table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1031d067-8898-4a97-8177-3a2b8eb83cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+---+----------+---------+--------------------+--------------------+----------+\n",
      "|           kafka_key|kafka_offset| id|first_name|last_name|               email|          created_at|updated_at|\n",
      "+--------------------+------------+---+----------+---------+--------------------+--------------------+----------+\n",
      "|{\"schema\":{\"type\"...|           2|  1|     Sally|   Thomas|sally.thomas@acme...|2022-05-01 14:33:...|      null|\n",
      "|{\"schema\":{\"type\"...|           6|  2|    George|   Bailey|  gbailey@foobar.com|2022-05-01 14:33:...|      null|\n",
      "|{\"schema\":{\"type\"...|           7|  3|    Edward|   Walker|       ed@walker.com|2022-05-01 14:33:...|      null|\n",
      "|{\"schema\":{\"type\"...|           8|  4|      Jonh|Kretchmar|  annek@noanswer.org|2022-05-01 14:33:...|      null|\n",
      "+--------------------+------------+---+----------+---------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfr = spark.read.format(\"delta\").load(location)\n",
    "dfr.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608eda90",
   "metadata": {},
   "source": [
    "Referências:\n",
    "https://docs.delta.io/latest/delta-batch.html#-ddlcreatetable\n",
    "https://docs.delta.io/latest/delta-constraints.html\n",
    "https://spark.apache.org/docs/3.1.1/sql-ref.html\n",
    "https://spark.apache.org/docs/3.1.1/sql-ref-syntax.html\n",
    "https://docs.delta.io/latest/best-practices.html\n",
    "https://debezium.io/documentation/reference/1.6/connectors/postgresql.html\n",
    "https://partners-intl.aliyun.com/help/doc-detail/141203.htm\n",
    "https://spark.apache.org/docs/3.1.1/structured-streaming-kafka-integration.html#content\n",
    "https://debezium.io/documentation/online-resources/\n",
    "https://github.com/suchitgupta01/spark-streaming-with-debezium\n",
    "https://suchit-g.medium.com/spark-streaming-with-kafka-connect-debezium-connector-ab9163808667\n",
    "https://stackoverflow.com/questions/62296734/how-to-transform-a-debezium-message-in-json-format-such-that-it-can-be-loaded-in\n",
    "https://github.com/kimaina/openmrs-elt\n",
    "https://sandeepkattepogu.medium.com/python-spark-transformations-on-kafka-data-8a19b498b32c\n",
    "https://spark.apache.org/docs/2.1.2/api/python/_modules/pyspark/sql/readwriter.html\n",
    "https://docs.delta.io/latest/quick-start.html#create-a-table&language-python\n",
    "https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.collect.html\n",
    "https://sparkbyexamples.com/pyspark/pyspark-collect/\n",
    "https://keestalkstech.com/2019/11/streaming-a-kafka-topic-to-a-delta-table-on-s3-with-spark-structured-streaming/ *****\n",
    "https://spark.apache.org/docs/latest/sql-data-sources-jdbc.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "e774977668b7c0ae8309835a5187aa7fbf7669e7d0bb59755bc63e573643edcd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
