version: '3.8'
services:
  db_source:
    image: 'postgres:15.3'
    container_name: cdc_postgresql
    hostname: db_source
    environment:
      POSTGRES_PASSWORD: example
      POSTGRES_USER: postgres
      POSTGRES_DB: postgres
    networks:
      vpc_cdc_pk:
        ipv4_address: 172.26.0.2
    volumes:
      - type: bind
        source: ./postgres/init
        target: /docker-entrypoint-initdb.d
      - type: bind
        source: ./postgres/conf/postgresql.conf
        target: /etc/postgresql/postgresql.conf
    command:
      - '-c'
      - config_file=/etc/postgresql/postgresql.conf
  cdc:
    image: 'debezium/server:2.3.1.Final'
    container_name: cdc_debezium
    hostname: cdc
    depends_on:
      - db_source
      - kafka-1
    networks:
      vpc_cdc_pk:
        ipv4_address: 172.26.0.3
    volumes:
      - type: bind
        source: ./debezium/conf
        target: /debezium/conf
      - type: bind
        source: ./debezium/data
        target: /debezium/data
  kafka-1:
    image: 'confluentinc/cp-server:7.2.6'
    hostname: kafka-1
    container_name: cdc_kafka1
    env_file:
      - ./kafka/kafka.env
    volumes:
      - type: bind
        source: ./kafka/update_run.sh
        target: /tmp/update_run.sh
    command: 'bash -c ''if [ ! -f /tmp/update_run.sh ]; then echo "ERROR: Did you forget the update_run.sh file that came with this docker-compose.yml file?" && exit 1 ; else /tmp/update_run.sh && /etc/confluent/docker/run ; fi'''
    networks:
      vpc_cdc_pk:
        ipv4_address: 172.26.0.5
  jupyter-spark:
    build:
      context: .
      dockerfile: jupyter.Dockerfile
    container_name: cdc_jupyter_spark
    hostname: jupyter_spark
    ports:
      - '9888:8888'
      - '4040:4040'
    environment:
      - SPARK_MASTER=local
      - SPARK_LOCAL_HOSTNAME=localhost
    networks:
      vpc_cdc_pk:
        ipv4_address: 172.26.0.6
    command: start.sh jupyter lab --LabApp.token='example'
    volumes:
      - type: bind
        source: ./jupyter_spark/work
        target: /home/jovyan/work
      - type: bind
        source: ./jupyter_spark/delta_lake
        target: /delta_lake
networks:
  vpc_cdc_pk:
    driver: bridge
    ipam:
      config:
        - subnet: 172.26.0.0/16
          gateway: 172.26.0.1
