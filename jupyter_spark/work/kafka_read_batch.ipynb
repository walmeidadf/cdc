{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b3a2c21-e00f-482e-b599-d8b4643cbb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4298d00-ac69-49b8-b62c-0f479af0c4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.1 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0b0c18c-b08f-43ee-a917-5a0d8800462e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "declare -x APACHE_SPARK_VERSION=\"3.2.1\"\n",
      "declare -x HOSTNAME=\"jupyter_spark\"\n",
      "declare -x PATH=\"/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/spark/bin\"\n",
      "declare -x PYSPARK_PYTHONPATH_SET=\"1\"\n",
      "declare -x PYTHONPATH=\"/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip:/usr/local/spark/python:\"\n",
      "declare -x SPARK_CONF_DIR=\"/usr/local/spark/conf\"\n",
      "declare -x SPARK_HOME=\"/usr/local/spark\"\n",
      "declare -x SPARK_LOCAL_HOSTNAME=\"localhost\"\n",
      "declare -x SPARK_MASTER=\"local\"\n",
      "declare -x SPARK_OPTS=\"--driver-java-options=-Xms1024M --driver-java-options=-Xmx4096M --driver-java-options=-Dlog4j.logLevel=info\"\n"
     ]
    }
   ],
   "source": [
    "!export | grep -i spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "241a3957-b1e9-4f2b-bad5-67acd4a21940",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.1\") \\\n",
    "    .appName(\"LabCDC\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2f02ae9-1101-4489-bdcf-21622d2c92b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://localhost:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>LabCDC</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=LabCDC>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark._sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85b62688-05d8-4520-90b9-35190ae9702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark \\\n",
    "  .read \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"kafka-1:9092\") \\\n",
    "  .option(\"subscribe\", \"lab_cdc.inventory.customers\") \\\n",
    "  .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec02516d-c3b7-451f-ac12-d0bc0cb33ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c297381-b394-41ae-b403-976bd9fb55bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: string, value: string]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5bcd3b76-46a7-4bee-934d-fe50a385f5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, list, pyspark.sql.types.Row)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coletandos os dados em lista de Row objects\n",
    "kafka_data = df.collect()\n",
    "len(kafka_data), type(kafka_data), type(kafka_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "174c3f5f-417e-48fe-8da3-f564d1267cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Topic:          lab_cdc.inventory.customers\n",
      " Partition:      2\n",
      " Offset:         0\n",
      " Timestamp:      2022-04-18 21:54:57.071000\n",
      " Timestamp Type: 0\n"
     ]
    }
   ],
   "source": [
    "# visalizando os valores das chanves topic, partition, offset, timestamp, timestampType\n",
    "print(' Topic:          {}\\n'.format(kafka_data[0]['topic']),\\\n",
    "      'Partition:      {}\\n'.format(kafka_data[0]['partition']),\\\n",
    "      'Offset:         {}\\n'.format( kafka_data[0]['offset']),\\\n",
    "      'Timestamp:      {}\\n'.format(kafka_data[0]['timestamp']),\\\n",
    "      'Timestamp Type: {}'.format(kafka_data[0]['timestampType']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3a8f6be-5a19-434f-a9e0-3913b273417b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key\n",
      " {\n",
      "    \"payload\": {\n",
      "        \"id\": 2\n",
      "    },\n",
      "    \"schema\": {\n",
      "        \"fields\": [\n",
      "            {\n",
      "                \"default\": 0,\n",
      "                \"field\": \"id\",\n",
      "                \"optional\": false,\n",
      "                \"type\": \"int32\"\n",
      "            }\n",
      "        ],\n",
      "        \"name\": \"lab_cdc.inventory.customers.Key\",\n",
      "        \"optional\": false,\n",
      "        \"type\": \"struct\"\n",
      "    }\n",
      "} \n",
      "\n",
      "Value\n",
      " {\n",
      "    \"payload\": {\n",
      "        \"after\": {\n",
      "            \"email\": \"gbailey@foobar.com\",\n",
      "            \"first_name\": \"George\",\n",
      "            \"id\": 2,\n",
      "            \"last_name\": \"Bailey\"\n",
      "        },\n",
      "        \"before\": null,\n",
      "        \"op\": \"r\",\n",
      "        \"source\": {\n",
      "            \"connector\": \"postgresql\",\n",
      "            \"db\": \"postgres\",\n",
      "            \"lsn\": 24278656,\n",
      "            \"name\": \"lab_cdc\",\n",
      "            \"schema\": \"inventory\",\n",
      "            \"sequence\": \"[null,\\\"24278656\\\"]\",\n",
      "            \"snapshot\": \"true\",\n",
      "            \"table\": \"customers\",\n",
      "            \"ts_ms\": 1650318888394,\n",
      "            \"txId\": 737,\n",
      "            \"version\": \"1.8.1.Final\",\n",
      "            \"xmin\": null\n",
      "        },\n",
      "        \"transaction\": null,\n",
      "        \"ts_ms\": 1650318888394\n",
      "    },\n",
      "    \"schema\": {\n",
      "        \"fields\": [\n",
      "            {\n",
      "                \"field\": \"before\",\n",
      "                \"fields\": [\n",
      "                    {\n",
      "                        \"default\": 0,\n",
      "                        \"field\": \"id\",\n",
      "                        \"optional\": false,\n",
      "                        \"type\": \"int32\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"first_name\",\n",
      "                        \"optional\": true,\n",
      "                        \"type\": \"string\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"last_name\",\n",
      "                        \"optional\": true,\n",
      "                        \"type\": \"string\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"email\",\n",
      "                        \"optional\": true,\n",
      "                        \"type\": \"string\"\n",
      "                    }\n",
      "                ],\n",
      "                \"name\": \"lab_cdc.inventory.customers.Value\",\n",
      "                \"optional\": true,\n",
      "                \"type\": \"struct\"\n",
      "            },\n",
      "            {\n",
      "                \"field\": \"after\",\n",
      "                \"fields\": [\n",
      "                    {\n",
      "                        \"default\": 0,\n",
      "                        \"field\": \"id\",\n",
      "                        \"optional\": false,\n",
      "                        \"type\": \"int32\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"first_name\",\n",
      "                        \"optional\": true,\n",
      "                        \"type\": \"string\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"last_name\",\n",
      "                        \"optional\": true,\n",
      "                        \"type\": \"string\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"email\",\n",
      "                        \"optional\": true,\n",
      "                        \"type\": \"string\"\n",
      "                    }\n",
      "                ],\n",
      "                \"name\": \"lab_cdc.inventory.customers.Value\",\n",
      "                \"optional\": true,\n",
      "                \"type\": \"struct\"\n",
      "            },\n",
      "            {\n",
      "                \"field\": \"source\",\n",
      "                \"fields\": [\n",
      "                    {\n",
      "                        \"field\": \"version\",\n",
      "                        \"optional\": false,\n",
      "                        \"type\": \"string\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"connector\",\n",
      "                        \"optional\": false,\n",
      "                        \"type\": \"string\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"name\",\n",
      "                        \"optional\": false,\n",
      "                        \"type\": \"string\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"ts_ms\",\n",
      "                        \"optional\": false,\n",
      "                        \"type\": \"int64\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"default\": \"false\",\n",
      "                        \"field\": \"snapshot\",\n",
      "                        \"name\": \"io.debezium.data.Enum\",\n",
      "                        \"optional\": true,\n",
      "                        \"parameters\": {\n",
      "                            \"allowed\": \"true,last,false,incremental\"\n",
      "                        },\n",
      "                        \"type\": \"string\",\n",
      "                        \"version\": 1\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"db\",\n",
      "                        \"optional\": false,\n",
      "                        \"type\": \"string\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"sequence\",\n",
      "                        \"optional\": true,\n",
      "                        \"type\": \"string\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"schema\",\n",
      "                        \"optional\": false,\n",
      "                        \"type\": \"string\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"table\",\n",
      "                        \"optional\": false,\n",
      "                        \"type\": \"string\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"txId\",\n",
      "                        \"optional\": true,\n",
      "                        \"type\": \"int64\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"lsn\",\n",
      "                        \"optional\": true,\n",
      "                        \"type\": \"int64\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"xmin\",\n",
      "                        \"optional\": true,\n",
      "                        \"type\": \"int64\"\n",
      "                    }\n",
      "                ],\n",
      "                \"name\": \"io.debezium.connector.postgresql.Source\",\n",
      "                \"optional\": false,\n",
      "                \"type\": \"struct\"\n",
      "            },\n",
      "            {\n",
      "                \"field\": \"op\",\n",
      "                \"optional\": false,\n",
      "                \"type\": \"string\"\n",
      "            },\n",
      "            {\n",
      "                \"field\": \"ts_ms\",\n",
      "                \"optional\": true,\n",
      "                \"type\": \"int64\"\n",
      "            },\n",
      "            {\n",
      "                \"field\": \"transaction\",\n",
      "                \"fields\": [\n",
      "                    {\n",
      "                        \"field\": \"id\",\n",
      "                        \"optional\": false,\n",
      "                        \"type\": \"string\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"total_order\",\n",
      "                        \"optional\": false,\n",
      "                        \"type\": \"int64\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"field\": \"data_collection_order\",\n",
      "                        \"optional\": false,\n",
      "                        \"type\": \"int64\"\n",
      "                    }\n",
      "                ],\n",
      "                \"optional\": true,\n",
      "                \"type\": \"struct\"\n",
      "            }\n",
      "        ],\n",
      "        \"name\": \"lab_cdc.inventory.customers.Envelope\",\n",
      "        \"optional\": false,\n",
      "        \"type\": \"struct\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# visualizando os valores das chaves Key e Value\n",
    "print('Key\\n', json.dumps(json.loads(kafka_data[0]['key']), indent=4, sort_keys=True), \\\n",
    "      '\\n\\nValue\\n',  json.dumps(json.loads(kafka_data[0]['value']), indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07bb9a05-c4d1-4d25-ad02-3dbac9c8d916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'before': None,\n",
       " 'after': {'id': 2,\n",
       "  'first_name': 'George',\n",
       "  'last_name': 'Bailey',\n",
       "  'email': 'gbailey@foobar.com'},\n",
       " 'source': {'version': '1.8.1.Final',\n",
       "  'connector': 'postgresql',\n",
       "  'name': 'lab_cdc',\n",
       "  'ts_ms': 1650318888394,\n",
       "  'snapshot': 'true',\n",
       "  'db': 'postgres',\n",
       "  'sequence': '[null,\"24278656\"]',\n",
       "  'schema': 'inventory',\n",
       "  'table': 'customers',\n",
       "  'txId': 737,\n",
       "  'lsn': 24278656,\n",
       "  'xmin': None},\n",
       " 'op': 'r',\n",
       " 'ts_ms': 1650318888394,\n",
       " 'transaction': None}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(kafka_data[0]['value'])['payload']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0787d80f-1aca-4b99-bcae-9449abeba34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['before', 'after', 'source', 'op', 'ts_ms', 'transaction'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(kafka_data[0]['value'])['payload'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49de2cae-18ae-467d-97ba-4f1bb3473a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(kafka_data[0]['value'])['payload']['op']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d97da41-5401-45e9-9d35-f2363655ae60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 2,\n",
       " 'first_name': 'George',\n",
       " 'last_name': 'Bailey',\n",
       " 'email': 'gbailey@foobar.com'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(kafka_data[0]['value'])['payload']['after']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b670317-d66d-427e-b38a-dd6c915094be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'version': '1.8.1.Final',\n",
       " 'connector': 'postgresql',\n",
       " 'name': 'lab_cdc',\n",
       " 'ts_ms': 1650318888394,\n",
       " 'snapshot': 'true',\n",
       " 'db': 'postgres',\n",
       " 'sequence': '[null,\"24278656\"]',\n",
       " 'schema': 'inventory',\n",
       " 'table': 'customers',\n",
       " 'txId': 737,\n",
       " 'lsn': 24278656,\n",
       " 'xmin': None}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(kafka_data[0]['value'])['payload']['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fa39dc21-2c20-49a4-b048-bc68b582c744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r 2 George Bailey gbailey@foobar.com\n",
      "r 3 Edward Walker ed@walker.com\n",
      "r 4 Jonh Kretchmar annek@noanswer.org\n",
      "r 1 Sally Thomas sally.thomas@acme.com\n"
     ]
    }
   ],
   "source": [
    "for row in kafka_data:\n",
    "    # print(str(row[0]) + \",\" + str(row[1]))\n",
    "    json_value = json.loads(row[1])\n",
    "    # print(json_value['payload'])\n",
    "    op         = json_value['payload']['op']\n",
    "    user_id    = json_value['payload']['after']['id']\n",
    "    first_name = json_value['payload']['after']['first_name']\n",
    "    last_name  = json_value['payload']['after']['last_name']\n",
    "    email      = json_value['payload']['after']['email']\n",
    "    print(op, user_id, first_name, last_name, email)\n",
    "    # print(json_value['payload']['op'] + \",\" + str(json_value['payload']['id']) + \",\" + json_value['payload']['first_name'] + \",\" + json_value['payload']['last_name'] + \",\" + json_value['payload']['email'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad8c288-eca0-4088-a3b6-443a7335cd87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01037eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_delta_log\n"
     ]
    }
   ],
   "source": [
    "output_table_basedir = '/spark_files'\n",
    "output_table = \"%s/delta-table\" % output_table_basedir\n",
    "\n",
    "# CREATE TABLE IF NOT EXISTS customers\n",
    "# CREATE OR REPLACE TABLE customers\n",
    "sql_customers_df = spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS customers (\n",
    "  id LONG NOT NULL,\n",
    "  first_name STRING NOT NULL,\n",
    "  last_name STRING NOT NULL,\n",
    "  email STRING NOT NULL)\n",
    "USING DELTA\n",
    "LOCATION '%s/poc1/customers'\n",
    "\"\"\" % output_table_basedir)\n",
    "\n",
    "# sql_customers_df.show()\n",
    "!ls /spark_files/poc1/customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13dfc527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kafka postgresql dbservermysql_poc1 readStream poc1_inventory_mysql db_mysql_poc_1\n",
    "sql_kafka_customers_df = spark \\\n",
    "  .read \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"kafka_raiox:9092\") \\\n",
    "  .option(\"subscribe\", \"db_pg_poc1.inventory.customers\") \\\n",
    "  .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac0787f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                 key|               value|\n",
      "+--------------------+--------------------+\n",
      "|{\"schema\":{\"type\"...|{\"schema\":{\"type\"...|\n",
      "|{\"schema\":{\"type\"...|{\"schema\":{\"type\"...|\n",
      "|{\"schema\":{\"type\"...|{\"schema\":{\"type\"...|\n",
      "|{\"schema\":{\"type\"...|{\"schema\":{\"type\"...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_kafka_customers_df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "475e05a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+---------+------+--------------------+-------------+\n",
      "|                 key|               value|               topic|partition|offset|           timestamp|timestampType|\n",
      "+--------------------+--------------------+--------------------+---------+------+--------------------+-------------+\n",
      "|[7B 22 73 63 68 6...|[7B 22 73 63 68 6...|db_pg_poc1.invent...|        0|     0|2022-03-17 17:11:...|            0|\n",
      "|[7B 22 73 63 68 6...|[7B 22 73 63 68 6...|db_pg_poc1.invent...|        0|     1|2022-03-17 17:11:...|            0|\n",
      "|[7B 22 73 63 68 6...|[7B 22 73 63 68 6...|db_pg_poc1.invent...|        0|     2|2022-03-17 17:11:...|            0|\n",
      "|[7B 22 73 63 68 6...|[7B 22 73 63 68 6...|db_pg_poc1.invent...|        0|     3|2022-03-17 17:11:...|            0|\n",
      "+--------------------+--------------------+--------------------+---------+------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_kafka_customers_df.selectExpr(\"*\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0469e436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       4|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_kafka_customers_df.selectExpr(\"count(*)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80e96ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r,1001,Sally,Thomas,sally.thomas@acme.com\n",
      "r,1002,George,Bailey,gbailey@foobar.com\n",
      "r,1003,Edward,Walker,ed@walker.com\n",
      "r,1004,Anne,Kretchmar,annek@noanswer.org\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "result = sql_kafka_customers_df.selectExpr(\"key\", \"value\")\n",
    "data_collect = result.collect()\n",
    "\n",
    "for row in data_collect:\n",
    "    # print(str(row[0]) + \",\" + str(row[1]))\n",
    "    json_value = json.loads(row[1])\n",
    "    # print(json_value['payload'])\n",
    "    print(json_value['payload']['__op'] + \",\" + str(json_value['payload']['id']) + \",\" + json_value['payload']['first_name'] + \",\" + json_value['payload']['last_name'] + \",\" + json_value['payload']['email'])\n",
    "\n",
    "# print(result[0][\"payload\"])\n",
    "# print(result[1][\"payload\"])\n",
    "# result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f59fa314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'schema': {'type': 'struct',\n",
       "  'fields': [{'type': 'int32', 'optional': False, 'field': 'id'},\n",
       "   {'type': 'string', 'optional': False, 'field': 'first_name'},\n",
       "   {'type': 'string', 'optional': False, 'field': 'last_name'},\n",
       "   {'type': 'string', 'optional': False, 'field': 'email'},\n",
       "   {'type': 'string', 'optional': True, 'field': '__op'},\n",
       "   {'type': 'string', 'optional': True, 'field': '__table'},\n",
       "   {'type': 'int64', 'optional': True, 'field': '__lsn'},\n",
       "   {'type': 'int64', 'optional': True, 'field': '__source_ts_ms'},\n",
       "   {'type': 'string', 'optional': True, 'field': '__deleted'}],\n",
       "  'optional': False,\n",
       "  'name': 'db_pg_poc1.inventory.customers.Value'},\n",
       " 'payload': {'id': 1001,\n",
       "  'first_name': 'Sally',\n",
       "  'last_name': 'Thomas',\n",
       "  'email': 'sally.thomas@acme.com',\n",
       "  '__op': 'r',\n",
       "  '__table': 'customers',\n",
       "  '__lsn': 34393800,\n",
       "  '__source_ts_ms': 1647537117788,\n",
       "  '__deleted': 'false'}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(data_collect[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b86aafb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytearray(b'{\"schema\":{\"type\":\"struct\",\"fields\":[{\"type\":\"int32\",\"optional\":false,\"field\":\"id\"}],\"optional\":false,\"name\":\"db_pg_poc1.inventory.customers.Key\"},\"payload\":{\"id\":1001}}')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collect[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0be3fcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracao de schema dinamica\n",
    "def infer_schema_json(kafka_df):\n",
    "    df_json = (\n",
    "        # filter out empty values\n",
    "        sql_kafka_customers_df.withColumn(\"value\", pyspark.sql.functions.expr(\"string(value)\"))\n",
    "        .filter(pyspark.sql.functions.col(\"value\").isNotNull())\n",
    "        # get latestecord\n",
    "        .select(\"key\", pyspark.sql.functions.expr(\"struct(offset, value) r\"))\n",
    "        .groupBy(\"key\").agg(pyspark.sql.functions.expr(\"max(r) r\")) \n",
    "        .select(\"r.value\"))\n",
    "\n",
    "    # decode the json values\n",
    "    df_read = spark.read.json(df_json.rdd.map(lambda x: x.value), multiLine=True)\n",
    "\n",
    "    # drop corrupt records\n",
    "    if \"_corrupt_record\" in df_read.columns:\n",
    "        df_read = (df_read.filter(pyspark.sql.functions.col(\"_corrupt_record\").isNotNull()).drop(\"_corrupt_record\"))\n",
    "\n",
    "    # schema\n",
    "    return df_read.schema.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44d053a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(List(StructField(payload,StructType(List(StructField(__deleted,StringType,true),StructField(__lsn,LongType,true),StructField(__op,StringType,true),StructField(__source_ts_ms,LongType,true),StructField(__table,StringType,true),StructField(email,StringType,true),StructField(first_name,StringType,true),StructField(id,LongType,true),StructField(last_name,StringType,true))),true),StructField(schema,StructType(List(StructField(fields,ArrayType(StructType(List(StructField(field,StringType,true),StructField(optional,BooleanType,true),StructField(type,StringType,true))),true),true),StructField(name,StringType,true),StructField(optional,BooleanType,true),StructField(type,StringType,true))),true)))\n"
     ]
    }
   ],
   "source": [
    "# monta schema a partir de json\n",
    "topic_schema_txt = infer_schema_json(sql_kafka_customers_df)\n",
    "topic_schema = pyspark.sql.types.StructType.fromJson(json.loads(topic_schema_txt))\n",
    "print(topic_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b53406a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+--------------------+--------------------+--------------------+\n",
      "|           kafka_key|kafka_offset|            kafka_ts|             payload|              schema|\n",
      "+--------------------+------------+--------------------+--------------------+--------------------+\n",
      "|{\"schema\":{\"type\"...|           1|2021-06-11 21:03:...|{false, 34072456,...|{[{id, false, int...|\n",
      "|{\"schema\":{\"type\"...|           2|2021-06-11 21:03:...|{false, 34072456,...|{[{id, false, int...|\n",
      "|{\"schema\":{\"type\"...|           3|2021-06-11 21:03:...|{false, 34072456,...|{[{id, false, int...|\n",
      "|{\"schema\":{\"type\"...|           0|2021-06-11 21:03:...|{false, 34072456,...|{[{id, false, int...|\n",
      "+--------------------+------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cria dataframe intermediario (filter out empty values + get latest version of each record + convert to JSON with schema)\n",
    "sql_kafka_customers_df_new = sql_kafka_customers_df\\\n",
    "    .withColumn(\"value\", pyspark.sql.functions.expr(\"string(value)\"))\\\n",
    "    .filter(pyspark.sql.functions.col(\"value\").isNotNull())\\\n",
    "    .select(\\\n",
    "        pyspark.sql.functions.expr(\"offset as kafka_offset\"),\\\n",
    "        pyspark.sql.functions.expr(\"timestamp as kafka_ts\"),\\\n",
    "        pyspark.sql.functions.expr(\"string(key) as kafka_key\"),\\\n",
    "        \"value\")\\\n",
    "    .select(\"kafka_key\", pyspark.sql.functions.expr(\"struct(*) as r\"))\\\n",
    "    .groupBy(\"kafka_key\")\\\n",
    "    .agg(pyspark.sql.functions.expr(\"max(r) r\"))\\\n",
    "    .withColumn('value', pyspark.sql.functions.from_json(pyspark.sql.functions.col(\"r.value\"), topic_schema))\\\n",
    "    .select('r.kafka_key', 'r.kafka_offset', 'r.kafka_ts', 'value.*')\n",
    "sql_kafka_customers_df_new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c305d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria tabela se nao existir se baseando no schema do dataframe intermediario\n",
    "delta_location = '%s/poc1/kafka_customers' % output_table_basedir\n",
    "spark.createDataFrame([], sql_kafka_customers_df_new.schema)\\\n",
    " .write\\\n",
    " .option(\"mergeSchema\", \"true\")\\\n",
    " .format(\"delta\")\\\n",
    " .mode(\"append\")\\\n",
    " .save(delta_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7267aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge de tabela\n",
    "DeltaTable.forPath(spark, delta_location)\\\n",
    "   .alias(\"t\")\\\n",
    "   .merge(sql_kafka_customers_df_new.alias(\"s\"), \"s.kafka_key = t.kafka_key\")\\\n",
    "   .whenMatchedUpdateAll()\\\n",
    "   .whenNotMatchedInsertAll()\\\n",
    "   .execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09381f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+--------------------+--------------------+--------------------+\n",
      "|           kafka_key|kafka_offset|            kafka_ts|             payload|              schema|\n",
      "+--------------------+------------+--------------------+--------------------+--------------------+\n",
      "|{\"schema\":{\"type\"...|           0|2021-06-11 21:03:...|{false, 34072456,...|{[{id, false, int...|\n",
      "|{\"schema\":{\"type\"...|           3|2021-06-11 21:03:...|{false, 34072456,...|{[{id, false, int...|\n",
      "|{\"schema\":{\"type\"...|           1|2021-06-11 21:03:...|{false, 34072456,...|{[{id, false, int...|\n",
      "|{\"schema\":{\"type\"...|           2|2021-06-11 21:03:...|{false, 34072456,...|{[{id, false, int...|\n",
      "+--------------------+------------+--------------------+--------------------+--------------------+\n",
      "\n",
      "+------------+---------+--------+----+--------------+---------+--------------------+----------+----+---------+\n",
      "|kafka_offset|__deleted|   __lsn|__op|__source_ts_ms|  __table|               email|first_name|  id|last_name|\n",
      "+------------+---------+--------+----+--------------+---------+--------------------+----------+----+---------+\n",
      "|           0|    false|34072456|   r| 1623445425713|customers|sally.thomas@acme...|     Sally|1001|   Thomas|\n",
      "|           3|    false|34072456|   r| 1623445425722|customers|  annek@noanswer.org|      Anne|1004|Kretchmar|\n",
      "|           1|    false|34072456|   r| 1623445425720|customers|  gbailey@foobar.com|    George|1002|   Bailey|\n",
      "|           2|    false|34072456|   r| 1623445425721|customers|       ed@walker.com|    Edward|1003|   Walker|\n",
      "+------------+---------+--------+----+--------------+---------+--------------------+----------+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persisted_df = spark.read.format(\"delta\").load(delta_location)\n",
    "persisted_df.select(\"*\").show()\n",
    "persisted_df.select(\"kafka_offset\", \"payload.*\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c5cea22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql postgres@postgres_data_source\n",
    "-- DROP SCHEMA inventory_poc1;\n",
    "CREATE SCHEMA IF NOT EXISTS inventory_poc1 AUTHORIZATION postgres;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f34ffad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql postgres@postgres_data_source\n",
    "CREATE TABLE IF NOT EXISTS inventory_poc1.customers (\n",
    "\tid serial NOT NULL,\n",
    "\tfirst_name varchar(255) NOT NULL,\n",
    "\tlast_name varchar(255) NOT NULL,\n",
    "\temail varchar(255) NOT NULL,\n",
    "\tCONSTRAINT customers_email_key UNIQUE (email),\n",
    "\tCONSTRAINT customers_pkey PRIMARY KEY (id)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc898a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replica os dados para a tabela final\n",
    "mode = \"overwrite\"\n",
    "url = \"jdbc:postgresql://postgres_data_source/postgres\"\n",
    "properties = {\"user\": \"postgres\",\"password\": \"postgres\",\"driver\": \"org.postgresql.Driver\"}\n",
    "df = persisted_df.select(\"payload.id\", \"payload.first_name\", \"payload.last_name\", \"payload.email\")\\\n",
    "    .write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .option(\"dbtable\", \"inventory_poc1.customers\") \\\n",
    "    .option(\"user\", \"postgres\") \\\n",
    "    .option(\"password\", \"postgres\") \\\n",
    "    .option(\"truncate\", \"true\") \\\n",
    "    .mode(mode) \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ddb1999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>id</th>\n",
       "        <th>first_name</th>\n",
       "        <th>last_name</th>\n",
       "        <th>email</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1001</td>\n",
       "        <td>Sally</td>\n",
       "        <td>Thomas</td>\n",
       "        <td>sally.thomas@acme.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1004</td>\n",
       "        <td>Anne</td>\n",
       "        <td>Kretchmar</td>\n",
       "        <td>annek@noanswer.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1002</td>\n",
       "        <td>George</td>\n",
       "        <td>Bailey</td>\n",
       "        <td>gbailey@foobar.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1003</td>\n",
       "        <td>Edward</td>\n",
       "        <td>Walker</td>\n",
       "        <td>ed@walker.com</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(1001, 'Sally', 'Thomas', 'sally.thomas@acme.com'),\n",
       " (1004, 'Anne', 'Kretchmar', 'annek@noanswer.org'),\n",
       " (1002, 'George', 'Bailey', 'gbailey@foobar.com'),\n",
       " (1003, 'Edward', 'Walker', 'ed@walker.com')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql postgres@postgres_data_source\n",
    "SELECT id, first_name, last_name, email FROM inventory_poc1.customers;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608eda90",
   "metadata": {},
   "source": [
    "Referências:\n",
    "https://docs.delta.io/latest/delta-batch.html#-ddlcreatetable\n",
    "https://docs.delta.io/latest/delta-constraints.html\n",
    "https://spark.apache.org/docs/3.1.1/sql-ref.html\n",
    "https://spark.apache.org/docs/3.1.1/sql-ref-syntax.html\n",
    "https://docs.delta.io/latest/best-practices.html\n",
    "https://debezium.io/documentation/reference/1.6/connectors/postgresql.html\n",
    "https://partners-intl.aliyun.com/help/doc-detail/141203.htm\n",
    "https://spark.apache.org/docs/3.1.1/structured-streaming-kafka-integration.html#content\n",
    "https://debezium.io/documentation/online-resources/\n",
    "https://github.com/suchitgupta01/spark-streaming-with-debezium\n",
    "https://suchit-g.medium.com/spark-streaming-with-kafka-connect-debezium-connector-ab9163808667\n",
    "https://stackoverflow.com/questions/62296734/how-to-transform-a-debezium-message-in-json-format-such-that-it-can-be-loaded-in\n",
    "https://github.com/kimaina/openmrs-elt\n",
    "https://sandeepkattepogu.medium.com/python-spark-transformations-on-kafka-data-8a19b498b32c\n",
    "https://spark.apache.org/docs/2.1.2/api/python/_modules/pyspark/sql/readwriter.html\n",
    "https://docs.delta.io/latest/quick-start.html#create-a-table&language-python\n",
    "https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.collect.html\n",
    "https://sparkbyexamples.com/pyspark/pyspark-collect/\n",
    "https://keestalkstech.com/2019/11/streaming-a-kafka-topic-to-a-delta-table-on-s3-with-spark-structured-streaming/ *****\n",
    "https://spark.apache.org/docs/latest/sql-data-sources-jdbc.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "e774977668b7c0ae8309835a5187aa7fbf7669e7d0bb59755bc63e573643edcd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
